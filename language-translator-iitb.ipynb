{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Step 1: Install required packages (clean installation)\n!pip install --quiet git+https://github.com/VarunGumma/IndicTransToolkit.git --use-pep517\n!pip install --quiet transformers sentencepiece accelerate\n# Install the appropriate bitsandbytes version for GPU\n!pip install --quiet bitsandbytes","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T16:32:39.658011Z","iopub.execute_input":"2025-04-06T16:32:39.658295Z","iopub.status.idle":"2025-04-06T16:33:17.392272Z","shell.execute_reply.started":"2025-04-06T16:32:39.658274Z","shell.execute_reply":"2025-04-06T16:33:17.391338Z"}},"outputs":[{"name":"stdout","text":"  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.8/51.8 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.1/104.1 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m897.5/897.5 kB\u001b[0m \u001b[31m20.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25h  Building wheel for IndicTransToolkit (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n  Building wheel for indic-nlp-library-IT2 (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.0/76.0 MB\u001b[0m \u001b[31m21.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import torch\nimport warnings\nimport os\nfrom IndicTransToolkit.processor import IndicProcessor\nfrom transformers import AutoTokenizer, AutoModelForSeq2SeqLM\nfrom datasets import load_dataset\nfrom transformers import DataCollatorForSeq2Seq, Seq2SeqTrainer, Seq2SeqTrainingArguments\nfrom peft import get_peft_model, LoraConfig, prepare_model_for_kbit_training\n\n# Suppress warnings\nwarnings.filterwarnings(\"ignore\")\nos.environ[\"WANDB_DISABLED\"] = \"true\"\n\n# Check device\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nprint(f\"Using device: {device}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T16:34:12.384121Z","iopub.execute_input":"2025-04-06T16:34:12.384410Z","iopub.status.idle":"2025-04-06T16:34:35.066745Z","shell.execute_reply.started":"2025-04-06T16:34:12.384389Z","shell.execute_reply":"2025-04-06T16:34:35.065989Z"}},"outputs":[{"name":"stdout","text":"Using device: cuda\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"# Set model name\nmodel_name = \"prajdabre/rotary-indictrans2-en-indic-dist-200M\"\n\n# Initialize processor\nip = IndicProcessor(inference=True)\n\n# Initialize tokenizer with correct settings\ntokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n\n# Load dataset\nraw_datasets = load_dataset(\"cfilt/iitb-english-hindi\")\nprint(f\"Dataset loaded: {raw_datasets}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T16:34:55.205778Z","iopub.execute_input":"2025-04-06T16:34:55.206456Z","iopub.status.idle":"2025-04-06T16:35:04.316183Z","shell.execute_reply.started":"2025-04-06T16:34:55.206428Z","shell.execute_reply":"2025-04-06T16:35:04.315539Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/1.11k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"10646159710e45148e00e8729a105f25"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenization_indictrans.py:   0%|          | 0.00/8.04k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"312209f2bb9b4c4ea5bc5584a5e175c3"}},"metadata":{}},{"name":"stderr","text":"A new version of the following files was downloaded from https://huggingface.co/prajdabre/rotary-indictrans2-en-indic-dist-200M:\n- tokenization_indictrans.py\n. Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"dict.SRC.json:   0%|          | 0.00/645k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"50cd66cedcc94660a91c5929ae61f449"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"dict.TGT.json:   0%|          | 0.00/3.39M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fe53324c783c469c90ff431da9b5f4aa"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.SRC:   0%|          | 0.00/759k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d0446ecff4d5451f8a49f6a66ec8d8eb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.TGT:   0%|          | 0.00/3.26M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bbb5567181324db2aa4202dd89afb0f2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/96.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b6768d763f3543cdbeb4d1acd744bc0b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/3.14k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c776d54d14634989aa104baa55e72d31"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"dataset_infos.json:   0%|          | 0.00/953 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"86577bda98b347a587552fca6f527f14"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00000-of-00001.parquet:   0%|          | 0.00/190M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a28a4325e97844dab27600d4c6a77527"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"validation-00000-of-00001.parquet:   0%|          | 0.00/85.7k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5eb7d208413f4f71a617c1d104603114"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"test-00000-of-00001.parquet:   0%|          | 0.00/500k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3a01262b5ef14e4b853e4e26eba8882c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/1659083 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3213cf83523e4928b75afe5e3da0f30d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split:   0%|          | 0/520 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e45ad3c7b5eb4c62bae2dd038afc2b2d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/2507 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1b199608775e43b391850c8bc4906e04"}},"metadata":{}},{"name":"stdout","text":"Dataset loaded: DatasetDict({\n    train: Dataset({\n        features: ['translation'],\n        num_rows: 1659083\n    })\n    validation: Dataset({\n        features: ['translation'],\n        num_rows: 520\n    })\n    test: Dataset({\n        features: ['translation'],\n        num_rows: 2507\n    })\n})\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"# Define preprocessing function with proper target tokenization\ndef preprocess_function(examples):\n    # Unpack the dict-of-lists\n    translations = examples[\"translation\"]\n    en_sentences = [t[\"en\"] for t in translations]\n    hi_sentences = [t[\"hi\"] for t in translations]\n    \n    # Transliterate & normalize\n    inputs = ip.preprocess_batch(en_sentences, src_lang=\"eng_Latn\", tgt_lang=\"hin_Deva\")\n    targets = ip.preprocess_batch(hi_sentences, src_lang=\"hin_Deva\", tgt_lang=\"hin_Deva\")\n    \n    # Tokenize inputs\n    model_inputs = tokenizer(inputs, max_length=128, truncation=True)\n    \n    # Tokenize targets - properly handle target tokenization\n    labels = tokenizer(targets, max_length=128, truncation=True)\n    model_inputs[\"labels\"] = labels[\"input_ids\"]\n    \n    return model_inputs\n\n# Process datasets\nprint(\"Processing datasets...\")\ntokenized_datasets = raw_datasets.map(\n    preprocess_function,\n    batched=True,\n    remove_columns=[\"translation\"],  # Drop the original dict-column\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T16:36:13.011332Z","iopub.execute_input":"2025-04-06T16:36:13.011659Z","iopub.status.idle":"2025-04-06T16:55:03.541520Z","shell.execute_reply.started":"2025-04-06T16:36:13.011636Z","shell.execute_reply":"2025-04-06T16:55:03.540862Z"}},"outputs":[{"name":"stderr","text":"Parameter 'function'=<function preprocess_function at 0x7a71991d4b80> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\n","output_type":"stream"},{"name":"stdout","text":"Processing datasets...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/1659083 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cc08aeb8c0614e769914507440e5068a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/520 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9caf904805ec4c2fb57338109db22bbc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2507 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f672c453d9ad47888f9bc9171525c617"}},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"# # Create smaller datasets for experimentation\n# small_train = tokenized_datasets[\"train\"].shuffle(seed=42).select(range(50_000))  # 50k for training\n# small_val = tokenized_datasets[\"test\"].shuffle(seed=42).select(range(2_500))  # 2.5k for validation\n# print(f\"Training samples: {len(small_train)}, Validation samples: {len(small_val)}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T05:52:34.823935Z","iopub.execute_input":"2025-04-06T05:52:34.824271Z","iopub.status.idle":"2025-04-06T05:52:34.857638Z","shell.execute_reply.started":"2025-04-06T05:52:34.824241Z","shell.execute_reply":"2025-04-06T05:52:34.856915Z"}},"outputs":[{"name":"stdout","text":"Training samples: 50000, Validation samples: 2500\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"# Load model for training\nprint(\"Loading model for training...\")\n# Set this environment variable to avoid copying issues\nos.environ[\"HF_8BIT_SKIP_CONVERT_CHECK\"] = \"1\"\n\n# Load model in regular fp16 mode instead of 8-bit\nmodel = AutoModelForSeq2SeqLM.from_pretrained(\n    model_name,\n    torch_dtype=torch.float16 if device == \"cuda\" else torch.float32,\n    device_map=None,  # Load to CPU first\n    trust_remote_code=True,\n    state_dict=None  # Will force loading weights normally\n)\nif device == \"cuda\":\n    model = model.to(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T16:59:12.750569Z","iopub.execute_input":"2025-04-06T16:59:12.750897Z","iopub.status.idle":"2025-04-06T16:59:18.330544Z","shell.execute_reply.started":"2025-04-06T16:59:12.750872Z","shell.execute_reply":"2025-04-06T16:59:18.329668Z"}},"outputs":[{"name":"stdout","text":"Loading model for training...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.46k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8453a938fc644cf788a8a634dd2c4eeb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"configuration_rotary_indictrans.py:   0%|          | 0.00/6.56k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"03bf31b07a5d4557aa7ff881193e08da"}},"metadata":{}},{"name":"stderr","text":"A new version of the following files was downloaded from https://huggingface.co/prajdabre/rotary-indictrans2-en-indic-dist-200M:\n- configuration_rotary_indictrans.py\n. Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"modeling_rotary_indictrans.py:   0%|          | 0.00/68.6k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7ae002bb92954ecf88cd0531962b8691"}},"metadata":{}},{"name":"stderr","text":"A new version of the following files was downloaded from https://huggingface.co/prajdabre/rotary-indictrans2-en-indic-dist-200M:\n- modeling_rotary_indictrans.py\n. Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/847M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e26942c2ba3d44bea66db22d4a245623"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/163 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"55b661f770b64f2a869412fbea2b05b3"}},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"# Prepare model for training with LoRA\nif device == \"cuda\":\n    # Skip prepare_model_for_kbit_training since we're not loading in 8-bit/4-bit\n    # If you're not using quantization, you can omit this line\n    # model = prepare_model_for_kbit_training(model)\n    \n    # Identify the correct target modules for this model architecture\n    # Let's get the correct module names from the model\n    target_modules = []\n    for name, module in model.named_modules():\n        if \"q_proj\" in name or \"v_proj\" in name:\n            module_name = name.split('.')[-1]\n            if module_name not in target_modules:\n                target_modules.append(module_name)\n    \n    print(f\"Using LoRA target modules: {target_modules}\")\n    \n    # Configure LoRA\n    lora_cfg = LoraConfig(\n        r=8,\n        lora_alpha=32,\n        target_modules=target_modules,\n        lora_dropout=0.1,\n        bias=\"none\",\n        task_type=\"SEQ_2_SEQ_LM\",\n    )\n    \n    # Apply LoRA to model\n    model = get_peft_model(model, lora_cfg)\n    model.print_trainable_parameters()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T16:59:27.271482Z","iopub.execute_input":"2025-04-06T16:59:27.271917Z","iopub.status.idle":"2025-04-06T16:59:27.595635Z","shell.execute_reply.started":"2025-04-06T16:59:27.271882Z","shell.execute_reply":"2025-04-06T16:59:27.594897Z"}},"outputs":[{"name":"stdout","text":"Using LoRA target modules: ['v_proj', 'q_proj']\ntrainable params: 884,736 || all params: 212,661,248 || trainable%: 0.4160\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"# Data collator for dynamic padding\ndata_collator = DataCollatorForSeq2Seq(tokenizer, model=model)\n\n# Configure training arguments\ntraining_args = Seq2SeqTrainingArguments(\n    output_dir=\"./lora_iitb\",\n    per_device_train_batch_size=8 if device == \"cuda\" else 4,\n    gradient_accumulation_steps=4,\n    num_train_epochs=1,\n    learning_rate=3e-4,\n    optim=\"paged_adamw_8bit\" if device == \"cuda\" else \"adamw_torch\",\n    fp16=device == \"cuda\",\n    report_to=[\"none\"],\n    save_strategy=\"steps\",\n    save_steps=5000,\n    evaluation_strategy=\"steps\",\n    eval_steps=5000,\n    logging_steps=500,\n    load_best_model_at_end=True,\n    metric_for_best_model=\"eval_loss\",\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T16:59:34.342493Z","iopub.execute_input":"2025-04-06T16:59:34.342778Z","iopub.status.idle":"2025-04-06T16:59:34.377548Z","shell.execute_reply.started":"2025-04-06T16:59:34.342757Z","shell.execute_reply":"2025-04-06T16:59:34.376664Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"# Initialize trainer\ntrainer = Seq2SeqTrainer(\n    model=model,\n    args=training_args,\n    # train_dataset=small_train,\n    # eval_dataset=small_val,\n    train_dataset=tokenized_datasets[\"train\"],\n    eval_dataset=tokenized_datasets[\"test\"],\n    tokenizer=tokenizer,\n    data_collator=data_collator,\n)\n\n# Run training\nprint(\"Starting training...\")\ntrainer.train()\nprint(\"Training completed!\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T17:01:34.012322Z","iopub.execute_input":"2025-04-06T17:01:34.012642Z","execution_failed":"2025-04-06T19:07:49.256Z"}},"outputs":[{"name":"stdout","text":"Starting training...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='3770' max='25923' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [ 3770/25923 2:00:25 < 11:48:01, 0.52 it/s, Epoch 0.15/1]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table><p>"},"metadata":{}}],"execution_count":null},{"cell_type":"code","source":"# Save the fine-tuned model\nmodel.save_pretrained(\"./final_lora_iitb\")\ntokenizer.save_pretrained(\"./final_lora_iitb\")\nprint(\"Model saved!\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T06:23:48.388621Z","iopub.execute_input":"2025-04-06T06:23:48.388959Z","iopub.status.idle":"2025-04-06T06:23:48.819421Z","shell.execute_reply.started":"2025-04-06T06:23:48.388928Z","shell.execute_reply":"2025-04-06T06:23:48.818504Z"}},"outputs":[{"name":"stdout","text":"Model saved!\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"test_sentences = [\n    \"\"\"As I wandered through the bustling city streets on a warm, sunny afternoon, \n    the world around me seemed to hum with life. The vibrant colors of flowers blooming \n    in the meticulously maintained parks painted a vivid contrast against the steel and \n    glass of the towering skyscrapers that loomed above, reflecting the bright blue sky \n    in their countless windows. The sunlight, filtering through the canopy of leaves in \n    the small, scattered patches of greenery that dotted the city, cast dappled shadows \n    on the pavement below, where the rhythmic clatter of footsteps and the distant hum \n    of traffic merged into a soothing, urban symphony. Street performers, positioned at \n    nearly every corner, played their guitars, violins, and saxophones, their melodies \n    blending into a medley of sounds that flowed like a river through the streets, carried\n    by the laughter and chatter of people spilling out of bustling cafés and restaurants, \n    their faces alight with the joy of an afternoon well spent. Children raced through the \n    playgrounds, their laughter carried on the gentle breeze that occasionally swept \n    through the streets, bringing with it the scent of freshly baked bread from a nearby \n    bakery and the tang of street food sizzling on grills as vendors called out to passersby. \n    In the midst of all this vibrant activity, I found myself swept up in the energy of the \n    city, its pulse echoing in my ears as I walked along, watching the ever-changing tapestry\n    of life unfold before me. The city was a living, breathing organism, constantly in motion, \n    and I couldn’t help but marvel at how different this world felt from the one I had known \n    for so long. It hadn’t been that long ago, only a few months, that I had lived in the \n    countryside, surrounded by rolling hills and quiet fields that stretched as far as the \n    eye could see. The mornings there had always been peaceful, almost meditative in their \n    stillness, with only the soft rustle of leaves in the trees, the gentle whisper of the \n    wind as it passed through the tall grasses, and the occasional chirping of birds breaking \n    the silence. I would wake early, just as the first rays of sunlight crept over the horizon, \n    casting a soft, golden light over the landscape. The air would be cool and crisp, filled \n    with the earthy scent of dew-soaked soil and the faint aroma of wildflowers. Those mornings \n    had their own kind of beauty, a beauty that came from the quiet simplicity of nature, from \n    the feeling of being alone in the world, surrounded by nothing but the sounds of the earth \n    waking up. I would sit on the porch of my small cottage, with a cup of steaming coffee in \n    hand, and watch as the mist slowly lifted from the fields, revealing the distant outline \n    of the forest, where the trees stood tall and silent, like sentinels guarding the secrets \n    of the land. Sometimes, if I was lucky, I’d catch a glimpse of a deer or two grazing in the \n    distance, their sleek bodies moving gracefully through the tall grass, unaware of my presence. \n    But despite the peace and tranquility of the countryside, there had always been a part of me \n    that longed for something more, something beyond the quiet, predictable rhythm of rural life. \n    I had spent years surrounded by nature’s beauty, and while I had loved it, I had also begun \n    to feel a sense of restlessness, a yearning for the energy and excitement that only a city \n    could provide. So, when the opportunity came to move to the city, I had taken it without \n    hesitation, packing up my life into a few boxes and leaving behind the familiar comforts of \n    the countryside for the unknown adventures that awaited me in the bustling streets of urban \n    life. Now, as I walked through those very streets, I realized just how much my life had changed \n    in such a short time. The cit y was everything I had hoped it would be, and more. Every day \n    brought something new, something unexpected. One day, I might stumble upon a hidden café tucked \n    away in a narrow alley, its walls covered in ivy, serving the best espresso I had ever tasted. \n    The next, I might find myself standing in the middle of a street festival, surrounded by food \n    stalls offering dishes from every corner of the world, the air filled with the scent of spices \n    and grilled meats, while performers danced and played music in the center of the crowd, their \n    movements a celebration of culture and tradition. The people, too, were different. In the \n    countryside, I had known everyone—every face was familiar, every story already told. But here, \n    in the city, every person I passed was a mystery, a new story waiting to be discovered. There \n    were the artists, sitting in cafés sketching scenes from their imagination; the businesspeople, \n    hurrying to meetings with phones pressed to their ears, their faces a mask of determination; \n    the students, gathered in groups, discussing everything from philosophy to the latest fashion \n    trends; and the tourists, cameras slung around their necks, eyes wide with wonder as they took \n    in the sights of the city. Each of them was on their own journey, their paths crossing with \n    mine for just a brief moment before they continued on their way, leaving behind only the faintest \n    trace of their presence. Yet, despite all the excitement and energy of the city, there were \n    still moments when I found myself missing the quiet solitude of the countryside. There were \n    times, late at night, when the city had finally quieted down, and I would lie awake in my small \n    apartment, listening to the distant sounds of cars passing by on the streets below, that I \n    would think back to those early mornings in the countryside, to the feeling of peace that came \n    from being alone with nature. I would remember the way the first light of dawn had turned the \n    sky a soft shade of pink, the way the wind had whispered through the trees, and the way the \n    world had felt so still, as if it were holding its breath, waiting for the day to begin. But \n    then the sun would rise, casting its golden light over the city once again, and I would step \n    outside, greeted by the sights and sounds of life unfolding around me, and I would remember \n    why I had chosen to leave the quiet behind. The city, with all its noise, its chaos, and its \n    constant movement, had a magic of its own, a magic that drew me in and made me feel alive in \n    a way that the countryside never could. It was a place where anything seemed possible, where \n    every corner held the promise of something new, something unexpected. And as I continued to \n    walk through the streets that day, I knew that, despite the occasional longing for the peace \n    of the countryside, I had found a new home in the heart of the city, where the pulse of life \n    beat strong and steady, carrying me along with it.\"\"\"\n]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T06:23:54.668534Z","iopub.execute_input":"2025-04-06T06:23:54.668869Z","iopub.status.idle":"2025-04-06T06:23:54.674143Z","shell.execute_reply.started":"2025-04-06T06:23:54.668840Z","shell.execute_reply":"2025-04-06T06:23:54.673240Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"# Load the processor for inference\nip_test = IndicProcessor(inference=True)\n\n# Load the fine-tuned model for inference (merge LoRA weights)\nfrom peft import PeftModel, PeftConfig\n\n# Load base model\nbase_model = AutoModelForSeq2SeqLM.from_pretrained(\n    model_name,\n    torch_dtype=torch.float16 if device == \"cuda\" else torch.float32,\n    trust_remote_code=True,\n).to(device)\n\n# Load LoRA adapter\npeft_model = PeftModel.from_pretrained(base_model, \"./final_lora_iitb\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T06:24:42.515527Z","iopub.execute_input":"2025-04-06T06:24:42.515962Z","iopub.status.idle":"2025-04-06T06:24:44.297301Z","shell.execute_reply.started":"2025-04-06T06:24:42.515927Z","shell.execute_reply":"2025-04-06T06:24:44.296328Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"# Merge weights (optional for faster inference)\nmerged_model = peft_model.merge_and_unload()\n\n# Prepare input for translation\nbatch = ip_test.preprocess_batch(test_sentences, src_lang=\"eng_Latn\", tgt_lang=\"hin_Deva\")\nbatch = tokenizer(\n    batch, padding=\"longest\", truncation=True, max_length=2048, return_tensors=\"pt\"\n).to(device)\n\n# Generate translations\nwith torch.inference_mode():\n    outputs = merged_model.generate(\n        **batch,\n        num_beams=5,\n        length_penalty=1.0,\n        repetition_penalty=1.2,\n        max_new_tokens=2048,\n        early_stopping=True\n    )\n\n# Decode outputs\noutputs = tokenizer.batch_decode(\n    outputs, skip_special_tokens=True, clean_up_tokenization_spaces=True\n)\noutputs = ip_test.postprocess_batch(outputs, lang=\"hin_Deva\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T06:27:57.195051Z","iopub.execute_input":"2025-04-06T06:27:57.195513Z","iopub.status.idle":"2025-04-06T06:28:44.909577Z","shell.execute_reply.started":"2025-04-06T06:27:57.195468Z","shell.execute_reply":"2025-04-06T06:28:44.908801Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"print(\"Translation results:\")\nfor i, (src, tgt) in enumerate(zip(test_sentences, outputs)):\n    print(f\"Translation {i+1}: {tgt}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T06:29:14.252945Z","iopub.execute_input":"2025-04-06T06:29:14.253235Z","iopub.status.idle":"2025-04-06T06:29:14.258479Z","shell.execute_reply.started":"2025-04-06T06:29:14.253212Z","shell.execute_reply":"2025-04-06T06:29:14.257581Z"}},"outputs":[{"name":"stdout","text":"Translation results:\nTranslation 1: जैसे ही मैं एक गर्म, धूप भरी दोपहर को शहर की व्यस्त सड़कों पर घूम रहा था, मेरे चारों ओर की दुनिया जीवन से गूंज रही थी। सावधानीपूर्वक बनाए गए पार्कों में खिलते फूलों के जीवंत रंग उन ऊँचे गगनचुंबी इमारतों के स्टील और कांच के खिलाफ एक जीवंत विरोधाभास को चित्रित करते थे जो ऊपर झुके हुए थे, उनकी अनगिनत खिड़कियों में चमकीले नीले आकाश को प्रतिबिंबित करते थे। धूप, छोटे, बिखरे हुए हरियाली के टुकड़ों में पत्तियों की छतरी के माध्यम से छांटते हुए, नीचे फुटपाथ पर छायाएँ डालते हुए, जहां कदमों की लयबद्ध गड़गड़ाहट और दूर की ट्रैफिक की गूंज एक शांत, शहरी सिम्फनी में मिल जाती थी। लगभग हर कोने पर स्थित, सड़क के कलाकार अपने गिटार, वायलिन और सैक्सोफोन बजाते थे, उनकी धुनें सड़कों से एक नदी की तरह बहने वाली ध्वनियों के मिश्रण में मिल जाती थीं, जो भीड़भाड़ वाले कैफे और रेस्तरां से बाहर निकलने वाले लोगों की हंसी और बातचीत से भरी होती थीं, उनके चेहरे एक अच्छी तरह से बिताई गई दोपहर की खुशी से चमकते थे। बच्चे खेल के मैदानों में दौड़ते थे, उनकी हंसी कभी-कभी सड़कों पर बहने वाली हल्की हवा पर चलती थी, अपने साथ पास की बेकरी से ताजा बेक की गई रोटी की खुशबू लाती थी और विक्रेताओं द्वारा राहगीरों को बुलाए जाने पर ग्रिल पर सिज़लिंग स्ट्रीट फूड की टांग लाती थी। इस सभी जीवंत गतिविधि के बीच, मैं शहर की ऊर्जा में डूबा हुआ पाया, इसकी नाड़ी मेरे कानों में गूंजती थी जब मैं आगे बढ़ता था, मेरे सामने जीवन की हमेशा बदलती हुई टेपेस्ट्री को देखते हुए। शहर एक जीवित, सांस लेने वाला जीव था, लगातार गति में, और मैं इस बात पर आश्चर्यचकित होते कि यह दुनिया उस दुनिया से कितनी अलग महसूस होती थी जिसे मैं इतने लंबे समय से जानता था। यह बहुत पहले नहीं हुआ था, केवल कुछ महीने पहले, जब मैं ग्रामीण इलाकों में रहता था, लुढ़कती पहाड़ियों और शांत खेतों से घिरा हुआ था जो आंखों तक फैलते थे। वहां की सुबह हमेशा शांतिपूर्ण रही थी, अपनी स्थिरता में लगभग ध्यानमग्न, पेड़ों में पत्तियों की नरम गड़गड़ाहट के साथ, हवा की हल्की फुसफुसाहट के साथ जब यह ऊँची घासों से गुजरती थी, और कभी-कभी पक्षियों की चिल्लाहट जो चुप्पी तोड़ती थी। मैं जल्दी जागता था, जैसे ही सूरज की रोशनी की पहली किरणें क्षितिज पर चढ़ती थीं, परिदृश्य पर एक नरम, सुनहरा प्रकाश डालती थीं। हवा ठंडी और कुरकुरा होती, ओस से भीगी हुई मिट्टी की मिट्टी की सुगंध और जंगली फूलों की हल्की सुगंध से भरी होती थी। उन सुबहों की अपनी तरह की सुंदरता होती थी, एक सुंदरता जो प्रकृति की शांत सादगी से आती थी, दुनिया में अकेले होने की भावना से, केवल पृथ्वी की आवाज़ों से घिरी होती थी। मैं अपने छोटे से कॉटेज के बरामदे पर बैठता था, हाथ में एक कप गर्म कॉफी लेकर, और देखता था कि धुंध धीरे-धीरे खेतों से उठती है, जंगल की दूर की रूपरेखा को प्रकट करती है, जहां पेड़ ऊंचे और शांत खड़े होते हैं, जैसे ग्रामीण जीवन की शांत, अनुमानित लय से परे कुछ। मैंने वर्षों तक प्रकृति की सुंदरता से घिरा हुआ था, और जबकि मुझे यह पसंद था, मैंने भी बेचैनी की भावना महसूस करना शुरू कर दिया था, उस ऊर्जा और उत्साह की लालसा जो केवल एक शहर ही प्रदान कर सकता था। इसलिए, जब शहर में जाने का अवसर आया, तो मैंने इसे बिना किसी हिचकिचाहट के लिया था, अपने जीवन को कुछ डिब्बों में पैक किया था और शहरी जीवन की व्यस्त सड़कों में मेरा इंतजार करने वाले अज्ञात रोमांचों के लिए ग्रामीण इलाकों की परिचित सुविधाओं को पीछे छोड़ दिया था। अब, जब मैं उन सड़कों से गुजर रहा था, तो मुझे एहसास हुआ कि इतनी कम समय में मेरी जिंदगी कितनी बदल गई थी। सिट वाई सब कुछ था जिसकी मैंने उम्मीद की थी, और भी अधिक। हर दिन कुछ नया, कुछ अप्रत्याशित लाया था। एक दिन, मैं एक संकीर्ण गली में छिपे हुए कैफे पर ठोकर खा सकता था, इसकी दीवारें आइवी से ढकी हुई थीं, जो मेरे द्वारा चखे गए सबसे अच्छे एस्प्रेसो की सेवा करती थीं। अगले दिन, मैं खुद को एक सड़क उत्सव के बीच में खड़ा पा सकता था, दुनिया के हर कोने से व्यंजन पेश करने वाले खाद्य स्टॉलों से घिरा हुआ, मसालों और ग्रिल्ड मांस की सुगंध से भरी हवा, जबकि कलाकार भीड़ के केंद्र में नाचते और संगीत बजाते थे, उनकी गतिविधियाँ संस्कृति और परंपरा का उत्सव थीं। लोग भी अलग थे। ग्रामीण इलाकों में, मैंने सभी को जाना था-हर चेहरा परिचित था, हर कहानी पहले से ही बताई गई थी। लेकिन यहां, शहर में, हर व्यक्ति जो मैं गुजरता था, एक रहस्य था, एक नई कहानी जो खोजे जाने का इंतजार कर रही थी। वहां कलाकार थे, कैफे में बैठकर अपनी कल्पना से दृश्य स्केच कर रहे थे; व्यवसायी, अपने कानों पर दबाए गए फोन के साथ बैठकों की ओर तेजी से बढ़ रहे थे, उनके चेहरे दृढ़ संकल्प का मुखौटा थे; छात्र, समूहों में इकट्ठा हुए, दर्शन से लेकर नवीनतम फैशन रुझानों तक सब कुछ चर्चा कर रहे थे; और पर्यटक, कैमरे अपने गले में लटक रहे थे, आश्चर्य से आंखें चौड़ी कर रहे थे जब वे शहर के दृश्यों को देख रहे थे। उनमें से प्रत्येक अपनी यात्रा पर था, उनके रास्ते बस एक संक्षिप्त क्षण के लिए मेरे साथ पार हो रहे थे, इससे पहले कि वे अपने रास्ते पर चलते रहे, केवल अपनी उपस्थिति का सबसे हल्का निशान छोड़ते हुए। फिर भी, शहर की सभी उत्तेजना और ऊर्जा के बावजूद, ऐसे क्षण भी थे जब मैं खुद को ग्रामीण इलाकों के शांत एकांत को याद करता था। कभी-कभी, देर रात को, जब शहर अंततः शांत हो गया था, और मैं अपने छोटे से अपार्टमेंट में जागता रहता, नीचे की सड़कों पर गुजरने वाली कारों की दूर की आवाज़ें सुनता, कि मैं ग्रामीण इलाकों की उन शुरुआती सुबहों को सोचूंगा, उस शांति की भावना को जो प्रकृति के साथ अकेले रहने से आती थी। मुझे याद होगा कि सुबह की पहली रोशनी ने आकाश को गुलाबी की नरम छाया कैसे बदल दिया था, जिस तरह से हवा ने पेड़ों में फुसफुसाया था, और जिस तरह से दुनिया ने इतना शांत महसूस किया था, जैसे कि वह अपना सांस रोक रही थी, दिन शुरू होने का इंतजार कर रही थी। लेकिन फिर सूरज उगता, शहर पर एक बार फिर से अपनी सुनहरी रोशनी डालता, और मैं बाहर कदम रखता, अपने चारों ओर खुलते जीवन के दृश्यों और ध्वनियों से स्वागत करता, और मुझे याद होगा कि मैंने चुपचाप पीछे रहने का फैसला क्यों किया था। शहर, अपने सभी शोर, अपनी अराजकता, और अपने निरंतर आंदोलन के बावजूद, एक अपना जादू था, एक ऐसा जादू था जिसने मुझे आकर्षित किया और मुझे इस तरह से जीवित महसूस कराया कि ग्रामीण क्षेत्र कभी नहीं कर सकता था। यह एक ऐसी जगह थी जहां कुछ भी संभव लग रहा था, जहां हर कोने में कुछ नया, कुछ अप्रत्याशित होने का वादा था। और जैसे-जैसे मैं उस दिन सड़कों पर चलता रहा, मुझे पता था कि, ग्रामीण इलाकों की शांति की कभी-कभी लालसा के बावजूद, मुझे शहर के दिल में एक नया घर मिल गया था, जहां जीवन की धड़कन मजबूत और स्थिर धड़कती थी, मुझे इसके साथ ले जाती थी।\n","output_type":"stream"}],"execution_count":24},{"cell_type":"code","source":"# assume raw_datasets[\"test\"] is still around\ntest_src = [t[\"en\"] for t in raw_datasets[\"test\"][\"translation\"]]\ntest_ref = [t[\"hi\"] for t in raw_datasets[\"test\"][\"translation\"]]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T06:37:01.975820Z","iopub.execute_input":"2025-04-06T06:37:01.976242Z","iopub.status.idle":"2025-04-06T06:37:02.017088Z","shell.execute_reply.started":"2025-04-06T06:37:01.976204Z","shell.execute_reply":"2025-04-06T06:37:02.016326Z"}},"outputs":[],"execution_count":25},{"cell_type":"code","source":"from tqdm.auto import tqdm\n\n# batch size for inference\nbsz = 16\npredictions = []\n\nfor i in tqdm(range(0, len(test_src), bsz)):\n    batch_src = test_src[i : i+bsz]\n    # preprocess + tokenize\n    inputs = ip_test.preprocess_batch(batch_src, src_lang=\"eng_Latn\", tgt_lang=\"hin_Deva\")\n    tok = tokenizer(inputs, padding=\"longest\", truncation=True, max_length=512, return_tensors=\"pt\").to(device)\n    # generate\n    with torch.inference_mode():\n        outs = merged_model.generate(**tok, num_beams=5, max_new_tokens=256)\n    # decode + postprocess\n    dec = tokenizer.batch_decode(outs, skip_special_tokens=True)\n    dec = ip_test.postprocess_batch(dec, lang=\"hin_Deva\")\n    predictions.extend(dec)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T06:37:16.574385Z","iopub.execute_input":"2025-04-06T06:37:16.574735Z","iopub.status.idle":"2025-04-06T06:43:10.161615Z","shell.execute_reply.started":"2025-04-06T06:37:16.574709Z","shell.execute_reply":"2025-04-06T06:43:10.160496Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/157 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c5c24d4e1e144fad8c807e8b2a71d15e"}},"metadata":{}}],"execution_count":26},{"cell_type":"code","source":"!pip install --quiet evaluate sacrebleu bert-score\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T06:44:51.539472Z","iopub.execute_input":"2025-04-06T06:44:51.539815Z","iopub.status.idle":"2025-04-06T06:44:55.778319Z","shell.execute_reply.started":"2025-04-06T06:44:51.539790Z","shell.execute_reply":"2025-04-06T06:44:55.777431Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.1/61.1 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h","output_type":"stream"}],"execution_count":28},{"cell_type":"code","source":"import evaluate\nimport numpy as np\n\nbleu = evaluate.load(\"sacrebleu\")\nchrf = evaluate.load(\"chrf\")\nbertscore = evaluate.load(\"bertscore\")\n\n# sacreBLEU expects a list of lists of references\nbleu_res    = bleu.compute(predictions=predictions, references=[[r] for r in test_ref])\nchrf_res    = chrf.compute(predictions=predictions, references=test_ref)\nbertscore_res = bertscore.compute(predictions=predictions, references=test_ref, lang=\"hi\")\n\nprint(f\"BLEU:    {bleu_res['score']:.2f}\")\nprint(f\"chrF:    {chrf_res['score']:.2f}\")\nprint(f\"BERTScore F1: {np.mean(bertscore_res['f1']):.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T06:48:08.463542Z","iopub.execute_input":"2025-04-06T06:48:08.463931Z","iopub.status.idle":"2025-04-06T06:48:19.020956Z","shell.execute_reply.started":"2025-04-06T06:48:08.463902Z","shell.execute_reply":"2025-04-06T06:48:19.019979Z"}},"outputs":[{"name":"stdout","text":"BLEU:    26.67\nchrF:    53.98\nBERTScore F1: 0.8694\n","output_type":"stream"}],"execution_count":30}]}